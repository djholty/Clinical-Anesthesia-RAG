# ===============================================
# Sample Environment Variables
# ===============================================
# Copy this file to .env and fill in your actual values
# cp sample.env .env
# ===============================================

# ===============================================
# Core Directories (relative to project root)
# ===============================================
DB_DIR=./data/chroma_db
MARKDOWN_DIR=./data/ingested_documents
WATCH_DIRECTORY=./data/ingested_documents

# ===============================================
# PDF Watcher Configuration
# ===============================================
PDF_WATCH_DIRECTORY=./data/pdfs
MD_OUTPUT_DIR=./data/ingested_documents
PDF_QUIET_PERIOD_SECONDS=120
PDF_CONVERT_ON_STARTUP=false

# ===============================================
# Database Watcher Configuration
# ===============================================
QUIET_PERIOD_SECONDS=300
REBUILD_ON_STARTUP=false

# ===============================================
# API Keys & Tokens (REQUIRED - Get from respective services)
# ===============================================
# HuggingFace token for downloading embeddings model
# REQUIRED if using gated models (e.g., NeuML/pubmedbert-base-embeddings)
# Get your token at: https://huggingface.co/settings/tokens
# Some models like all-MiniLM-L6-v2 don't require a token
HF_TOKEN=your_huggingface_token_here

# ===============================================
# Embedding Model Configuration
# ===============================================
# Options (must be sentence-transformers compatible):
#
# GENERAL PURPOSE (fast, good for general text):
# - all-MiniLM-L6-v2 (default - fast, general purpose, ~80MB, 384 dims)
# - all-mpnet-base-v2 (better quality than MiniLM, ~420MB, 768 dims)
# - all-MiniLM-L12-v2 (better than L6, ~420MB, 384 dims)
#
# MEDICAL/CLINICAL (specialized for biomedical/clinical text, ~400-500MB, 768 dims):
# - pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb (BioBERT for sentence similarity - good for medical Q&A)
# - NeuML/pubmedbert-base-embeddings (PubMedBERT fine-tuned for embeddings - excellent for medical literature)
#   ⚠️ REQUIRES HF_TOKEN - this is a gated model
# - kamalkraj/BioSimCSE-BioLinkBERT-BASE (BioSimCSE - trained on biomedical texts, optimized for similarity)
# - pritamdeka/S-PubMedBert-MS-MARCO (PubMedBERT fine-tuned on MS-MARCO - good for medical retrieval)
# - gsarti/biobert-nli (BioBERT fine-tuned on SNLI/MultiNLI - good semantic understanding)
# - microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext (PubMedBERT from Microsoft - comprehensive biomedical)
#
# Note: Some models create a wrapper with mean pooling (that's OK - they still work)
# Note: Medical models are larger (~400-500MB) but provide better domain understanding
# Note: Changing the embedding model requires rebuilding the database
# IMPORTANT: Do NOT use quotes around the model name (e.g., use NeuML/pubmedbert-base-embeddings not 'NeuML/pubmedbert-base-embeddings')
# IMPORTANT: Some models (especially medical models) require HF_TOKEN authentication
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ===============================================
# Chunking Configuration
# ===============================================
# Chunk size: Number of characters per chunk (default: 2000)
# Smaller chunks (1000-1500): More granular, better for precise retrieval
# Medium chunks (2000): Balanced (default)
# Larger chunks (3000-4000): More context per chunk, fewer total chunks
CHUNK_SIZE=2000

# Chunk overlap: Number of characters to overlap between chunks (default: 300)
# Higher overlap (300-500): Better context continuity, more chunks
# Lower overlap (100-200): Fewer chunks, faster processing
# Recommended: 10-20% of chunk_size for medical text
CHUNK_OVERLAP=300

# Groq API key for LLM inference
GROQ_API_KEY=your_groq_api_key_here

# OpenAI API key (optional - only needed if ENABLE_PDF_CONVERSION=true)
OPENAI_API_KEY=your_openai_api_key_here

# ===============================================
# Admin Authentication (optional)
# ===============================================
ADMIN_USERNAME=admin
ADMIN_PASSWORD=your_admin_password_here
# Leave ADMIN_PASSWORD empty for open access (not recommended for production)

# ===============================================
# Frontend/API Configuration
# ===============================================
API_URL=http://127.0.0.1:8000

# ===============================================
# PDF Conversion Settings (optional)
# ===============================================
# Enable automatic PDF to Markdown conversion on upload
ENABLE_PDF_CONVERSION=false

# PDF conversion optimization settings
TABLE_CONCURRENCY=5
TABLE_DELAY_SECONDS=0

# ===============================================
# Legacy/Optional Settings
# ===============================================
OLD_DB_DIR=./data/optimized_2000_markdown_chroma_db

